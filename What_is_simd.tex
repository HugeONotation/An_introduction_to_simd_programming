\chapter{What is SIMD?}
Consider what forms of parallelism are available on contemporary computing
devices. It's likely that two main ideas come to mind: multithreading and
general-purpose GPU programming. However, there exists a lesser-known form of
parallelism available on our CPUs, SIMD instructions.

Before explaining these, it helps to establish a point of contrast. Consider
what using an add instruction looks like on a 32-bit machine. This instruction
would take its inputs from a pair of general purpose registers, 32-bits in size,
each storing one of the arguments to the addition operation. As the instruction
executes the sum of these two numbers is computed, and will be stored in a
32-bit general purpose register. This is what we'll refer to as a scalar add
instruction since it computes a single sum at a time.

However, many modern CPU ISAs feature vector registers and vector instructions,
meaning we can perform multiple 32-bit additions at once. In most contemporary
SIMD instruction sets, these vector registers are 128 bits in size, meaning they
can fit four 32-bit integers within them at a time. Correspondingly, such ISAs
feature vector add instructions which take these vector registers as operands
instead of general purpose registers. This allows them to compute four different
sums within one instruction. Often, these vector additions have the same latency
as scalar additions, effectively meaning a 4x increase in throughput (by one
admittedly narrow and simplified definition). On x86 CPUs, as would be used in
almost all personal laptop/desktop computers, 256-bit SIMD is widely available,
with 512-bit SIMD gaining ground. Correspondingly, this means 8x or even 16x
throughput increases.

It  must be admitted that this form of parallelism is not necessarily as high
throughput or as powerful as multithreading or GPU programming might be.
Certainly, a modern CPU may have more than 16 cores, and a GPU may handle more
than that many threads on one of its streaming multiprocessors. However, SIMD
instructions do have their own set of advantages.

First, SIMD is a much more fine-grained form of parallelism. This makes it
useful under circumstances where the overhead intrinsic to multithreading and
GPU programming would render them counter-productive. The overhead of launching
a thread, performing a context switch, or merely synchronizing data access
across multiple threads can greater than the benefit grained from
multithreading. Similarly, there is a substantial overhead to launching and
executing GPU kernels. Even an empty GPU kernel that does nothing can take
around 10 microseconds to execute (not including anything before or after, such
as the actual communication with the CPU). This is not to say that there is no
overhead to using SIMD. Vector instructions generally run on their own separate
set of execution units, which may be powered off when not in use, requiring a
startup time to be paid if they haven't been used previously. On certain CPUs,
the use of SIMD instructions will sometimes lead to preemptive downclocking.

A second broad advantage is the mere widespread availability of SIMD
instructions when compared to machines with several cores, or dedicate GPUs.
Basically any CPU that would be found in a dedicated consumer grade computing
device, whether a phone, tablet, laptop, or desktop will feature SIMD
instructions. In some sense, this makes SIMD a more reliable approach for
improving performance since its presence may be more reasonably assumed.
Assuming a certain amount of CPU cores or that users have dedicated GPUs is
unreasonable in most contexts however. 

Third, it is often the case that certain operations are only available as SIMD
instructions. For example, on x86 integer maximum, minimum, absolute value, and
average instructions are not available in scalar form, but have been available
in SIMD form for decades. Even more recently, x86 has gained specialized
instructions pertinent to the AES, SHA1, and SHA256 encryption algorithms, as
well as carry-less multiplications and bit shuffling operations (or rather
operations that are abused for that purpose). The use of these instructions may
lead to performance benefits beyond those gained just from the greater data
throughput. The instruction sequence itself may be shortened, sometimes greatly
so.

Yet despite these strengths, SIMD comes with a substantial set of practical
downsides. Merely developing a familiarity with SIMD is difficult as there are
substantially fewer resources for SIMD programming (a situation which motivates
the writing of this book). Using SIMD instructions also generally requires
consideration of the different CPU ISAs and microarchitectures that your
software will be targeting, since these factors will determine which SIMD
instruction sets are available. SIMD programming is itself generally not as
straightforward as typical scalar programming as most programming languages have
no dedicated facilities for it. 

\section{Flynn's Taxonomy}
All that said, what the term SIMD actually means has yet to be discussed. The
term originates from a taxonomic system introduced by Micheal J. Flynn in 1966,
what we now call Flynn's Taxonomy. This is a system for categorizing computer
architectures based on whether the machine processes singular or multiple
instruction/data streams. Although originally meant to describe physical
machines, this system of categorization is also applied to abstract machines and
to categorize forms of parallelism in general.

FLynn's taxonomy features the four following categories:

\textbf{Single-instruction, single-data (SISD)} The majority of all written code
is written in a SISD fashion. The instructions are part of a single instruction
stream and there is one stream of inputs. Although most modern computing
machines do have at least one form of parallelism available, the abstract
machine which most programming languages present would fall into the SISD
category.

\textbf{Single-instruction, multiple-data (SIMD)} SIMD is naturally the subject
of this text. Under this scheme, a single sequence of instructions is applied to
multiple sets of inputs at once. Although the focus here will be SIMD
instructions on CPUs, it should be noted that SIMD is perhaps most thoroughly
applied on GPU architectures, which not only make use of it as a core part of
their programming model, but also make use of it on multiple levels.

\textbf{Multiple-instruction, single-data (MISD)} This particular taxonomic
group sees relatively little group due to the unlikeness that multiple distinct
instruction streams have the same set of inputs. However, in situations where
safety is critical, MISD machines are sometimes used with the instruction
streams holding the same contents, and the same result getting computed merely
for the sake of redundancy.

\textbf{Multiple-instruction, multiple-data (MIMD)} Likely the second most
familiar group, MIMD sees widespread use due to multicore systems falling into
this category. With each core operating on its own instruction stream and set of
data. At the top-most level GPUs may also be placed under this category as they
feature multiple streaming multiprocessors, each processing their own
instruction stream, and each with their own set of data streams.

% \begin{center}
%   \begin{tabular}{ c | c c c }
%   & & \multicolumn{2}{c}{\textbf{Instruction Streams}} \\
%   \hline
%   & & Single & Multiple \\ 
%   \textbf{Data}    & Single   & SISD & MISD \\  
%   \textbf{Streams} & Multiple & SIMD & MIMD \\    
%   \end{tabular}
% \end{center}

\section{SWAR: SIMD Within a Register}
The particular brand of SIMD which modern CPUs leverage is commonly referred to
as SIMD within in a Register for very literal reasons. So it should be noted
that the term SIMD, as it is used throughout this work, will tend to refer to
this particular style of SIMD processing that's used available on cotemporary
hardware.

It should be noted however that the term SWAR is also applied to hacks which
rely on using wider types to process multiple smaller types in parallel. A very
simple example would be, given two arrays of eight 8-bit integers, then the
bitwise AND of both arrays could be computed all at once by loading the entire
arrays as 64-bit integers and utilizing a 64-bit wide AND instruction.

Although this seems like a fundamentally different approach, such techniques are
commonly used in conjunction with dedicated SIMD instructions, blurring the line
between what the two are.
